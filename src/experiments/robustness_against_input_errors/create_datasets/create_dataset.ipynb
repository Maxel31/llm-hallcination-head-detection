{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07ccf58a",
   "metadata": {},
   "source": [
    "## 実験用の誤りを含む/含まない文ペアデータセットを作成する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56741f06",
   "metadata": {},
   "source": [
    "データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bbdc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_typo_dataset_train = pd.read_json(\n",
    "    \"../../../../dataset/original/japanese_wikipedia_typo_dataset/train.jsonl\",\n",
    "    lines=True,\n",
    ")\n",
    "df_typo_dataset_test = pd.read_json(\n",
    "    \"../../../../dataset/original/japanese_wikipedia_typo_dataset/test.jsonl\",\n",
    "    lines=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7324df82",
   "metadata": {},
   "source": [
    "中身を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dea6258",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_typo_dataset_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73793044",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_typo_dataset_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527ab755",
   "metadata": {},
   "source": [
    "縦に結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f499ed96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセット結合\n",
    "df_typo_dataset = pd.concat(\n",
    "    [df_typo_dataset_train, df_typo_dataset_test], ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62cf0f6",
   "metadata": {},
   "source": [
    "タイポ部分までの文章を切り出す\n",
    "- \"diffs\":[{'pre':'token1', 'post':'token2'}]  \n",
    "の値をもとに、  \n",
    "'pre_text'と'post_text'について、それぞれ'token1'と'token2'より後の文字を削除する  \n",
    "(token1, token2 までは含める)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eb9f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_diff_position(text1: str, text2: str) -> int:\n",
    "    \"\"\"2つのテキストを比較して、最初に異なる文字の位置を返す\n",
    "\n",
    "    Args:\n",
    "        text1: 比較する1つ目のテキスト\n",
    "        text2: 比較する2つ目のテキスト\n",
    "\n",
    "    Returns:\n",
    "        最初に異なる文字の位置（インデックス）\n",
    "\n",
    "    \"\"\"\n",
    "    min_len = min(len(text1), len(text2))\n",
    "\n",
    "    for i in range(min_len):\n",
    "        if text1[i] != text2[i]:\n",
    "            return i\n",
    "\n",
    "    # 全て一致している場合は短い方の長さを返す\n",
    "    return min_len\n",
    "\n",
    "\n",
    "def extract_before_typo_token(\n",
    "    pre_text: str, post_text: str, diffs: list[dict], key: str\n",
    ") -> str:\n",
    "    \"\"\"pre_textとpost_textを比較し、diffs の値をもとに、タイポ部分までの文章を切り出す\n",
    "\n",
    "    （タイポトークンを含む）\n",
    "\n",
    "    Args:\n",
    "        pre_text: タイポ前のテキスト\n",
    "        post_text: タイポ後のテキスト\n",
    "        diffs: タイポ情報のリスト [{'pre': 'token1', 'post': 'token2'}, ...]\n",
    "        key: 'pre' または 'post' を指定\n",
    "\n",
    "    Returns:\n",
    "        タイポ部分までの文章（タイポトークンを含む）\n",
    "\n",
    "    \"\"\"\n",
    "    if not diffs:\n",
    "        return pre_text if key == \"pre\" else post_text\n",
    "\n",
    "    # 使用するテキストを選択\n",
    "    text = pre_text if key == \"pre\" else post_text\n",
    "\n",
    "    # 最初のdiffのトークンを取得\n",
    "    first_diff = diffs[0]\n",
    "    token = first_diff.get(key, \"\")\n",
    "\n",
    "    if not token:\n",
    "        return text\n",
    "\n",
    "    # pre_textとpost_textで異なる位置を見つける\n",
    "    diff_pos = find_diff_position(pre_text, post_text)\n",
    "\n",
    "    # 異なる位置からトークン長だけ取得して確認\n",
    "    token_len = len(token)\n",
    "    if diff_pos + token_len <= len(text):\n",
    "        actual_token = text[diff_pos : diff_pos + token_len]\n",
    "        if actual_token == token:\n",
    "            # トークンを含めてその位置までを返す\n",
    "            return text[: diff_pos + token_len]\n",
    "\n",
    "    # フォールバック: 最初の出現位置を使用\n",
    "    idx = text.find(token)\n",
    "    if idx != -1:\n",
    "        return text[: idx + len(token)]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45575cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_textとpost_textからタイポ部分までを抽出(diffsを使用、同じ位置で切り出し)\n",
    "df_typo_dataset[\"pre_text_truncated\"] = df_typo_dataset.apply(\n",
    "    lambda row: extract_before_typo_token(\n",
    "        row[\"pre_text\"], row[\"post_text\"], row[\"diffs\"], \"pre\"\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "df_typo_dataset[\"post_text_truncated\"] = df_typo_dataset.apply(\n",
    "    lambda row: extract_before_typo_token(\n",
    "        row[\"pre_text\"], row[\"post_text\"], row[\"diffs\"], \"post\"\n",
    "    ),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ecac2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_typo_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aee906",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_typo_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6b19ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_text_truncated と post_text_truncated の文字数が同じもののみ抽出\n",
    "df_typo_dataset = df_typo_dataset[\n",
    "    df_typo_dataset[\"pre_text_truncated\"].str.len()\n",
    "    == df_typo_dataset[\"post_text_truncated\"].str.len()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f717c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_typo_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9fd83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最小文字数の定義\n",
    "MIN_TEXT_LENGTH = 20\n",
    "\n",
    "# 最小文字数以上のデータに限定\n",
    "df_typo_dataset = df_typo_dataset[df_typo_dataset[\"pre_text_truncated\"].str.len() >= MIN_TEXT_LENGTH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738ad588",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_typo_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880b1025",
   "metadata": {},
   "source": [
    "保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999d01f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用するカラムだけ抽出\n",
    "df_typo_dataset = df_typo_dataset[\n",
    "    [\"category\", \"pre_text_truncated\", \"post_text_truncated\"]\n",
    "]\n",
    "\n",
    "# 名前の変更\n",
    "df_typo_dataset = df_typo_dataset.rename(\n",
    "    columns={\"pre_text_truncated\": \"typo_text\", \"post_text_truncated\": \"no_typo_text\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edffc5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_typo_dataset[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6535750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_typo_dataset.to_json(\n",
    "    \"../../../../dataset/robustness_against_input_errors/typo_dataset.jsonl\",\n",
    "    orient=\"records\",\n",
    "    lines=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}